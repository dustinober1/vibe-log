---
phase: 06-error-handling-hardening
plan: 06
type: execute
wave: 3
depends_on:
  - 04
  - 05
files_modified:
  - README.md
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Limitations section added to README near top"
    - "Multi-process limitation prominently documented"
    - "Docker deployment example provided"
    - "Kubernetes deployment example provided"
    - "Cloud logging patterns documented"
    - "Links to TROUBLESHOOTING.md and MONITORING.md added"
  artifacts:
    - path: "README.md"
      provides: "Updated README with limitations section and deployment examples"
      contains: "Limitations, Docker, Kubernetes, Cloud Logging"
  key_links:
    - from: "README.md"
      to: "docs/TROUBLESHOOTING.md"
      via: "troubleshooting guide link"
      pattern: "TROUBLESHOOTING\\.md"
    - from: "README.md"
      to: "docs/MONITORING.md"
      via: "monitoring guide link"
      pattern: "MONITORING\\.md"
---

<objective>
Update README.md with prominent limitations section, deployment examples for Docker and Kubernetes, and cloud logging patterns with links to troubleshooting and monitoring guides.

Purpose: Clearly document known limitations (especially multi-process), provide production deployment examples, and link to comprehensive documentation for production operators.

Output: Updated README.md with limitations section, deployment examples, and documentation links.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/06-error-handling-hardening/06-CONTEXT.md
@.planning/phases/06-error-handling-hardening/06-RESEARCH.md
@.planning/STATE.md
@.planning/phases/06-error-handling-hardening/06-04-SUMMARY.md
@.planning/phases/06-error-handling-hardening/06-05-SUMMARY.md

@README.md
</context>

<tasks>

<task type="auto">
  <name>Add prominent Limitations section to README</name>
  <files>README.md</files>
  <action>
    Add a Limitations section near the top of the README, after Features and before Transports.

    Insert after the "Extended Capabilities" section (around line 50):

    ```markdown
    ---

    ## Limitations

    **Multi-Process Writing: NOT SUPPORTED**

    log-vibe does **NOT** support multiple processes writing to the same log file. This is a known limitation that will cause:
    - Data corruption
    - Lost log entries
    - Rotation failures
    - Race conditions

    **Workarounds:**
    - Use separate log files per process: `./logs/app-${process.pid}.log`
    - Use a dedicated logging server (recommended for production)
    - Use syslog or external logging service

    See [Production Deployment](#production-deployment) for examples.

    **Other Limitations:**
    - No built-in log aggregation (use ELK, Splunk, etc.)
    - No structured logging output (plain text only)
    - No multi-process safe rotation

    ---

    ```

    This ensures users see the multi-process limitation prominently before using the library.
  </action>
  <verify>
    grep -n "Limitations\|Multi-Process.*NOT SUPPORTED" README.md | head -5
  </verify>
  <done>
    Limitations section added prominently in README
  </done>
</task>

<task type="auto">
  <name>Add Production Deployment section with examples</name>
  <files>README.md</files>
  <action>
    Add a Production Deployment section before the API section (around line 660, before "## API"):

    ```markdown
    ---

    ## Production Deployment

    ### Docker Deployment

    **Dockerfile example:**
    ```dockerfile
    FROM node:18-alpine

    WORKDIR /app

    # Copy package files
    COPY package*.json ./
    RUN npm ci --only=production

    # Copy application code
    COPY . .

    # Create log directory with proper permissions
    RUN mkdir -p /app/logs && \
        chown -R node:node /app/logs

    USER node

    # Health check
    HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
        CMD node -e "const fs=require('fs'); try{fs.statSync('/app/logs/app.log');process.exit(0)}catch{process.exit(1)}"

    CMD ["node", "index.js"]
    ```

    **docker-compose.yml example:**
    ```yaml
    version: '3.8'

    services:
      app:
        build: .
        volumes:
          # Persist logs outside container
          - ./logs:/app/logs
        environment:
          - NODE_ENV=production
        restart: unless-stopped
        healthcheck:
          test: ["CMD", "node", "-e", "require('fs').statSync('/app/logs/app.log')"]
          interval: 30s
          timeout: 3s
          retries: 3
    ```

    **Configuration for Docker:**
    ```typescript
    import { configure } from 'log-vibe';

    configure({
      file: '/app/logs/app.log',
      rotation: {
        maxSize: '100MB',
        pattern: 'daily',
        compressionLevel: 6,
        maxFiles: 20,
        maxAge: 30
      },
      console: false  // Disable console in production
    });
    ```

    ### Kubernetes Deployment

    **Deployment with persistent volume:**
    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: app
    spec:
      replicas: 3
      template:
        metadata:
          labels:
            app: myapp
        spec:
          containers:
          - name: app
            image: myapp:latest
            resources:
              requests:
                memory: "256Mi"
                cpu: "250m"
              limits:
                memory: "512Mi"
                cpu: "500m"
            volumeMounts:
            - name: logs
              mountPath: /app/logs
            env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          volumes:
          - name: logs
            emptyDir: {}  # or use PersistentVolumeClaim
    ```

    **Multi-pod logging (separate files per pod):**
    ```typescript
    import { configure } from 'log-vibe';

    // Use pod name or UID for separate log files
    const logFile = `/app/logs/app-${process.env.POD_NAME || 'default'}.log`;

    configure({
      file: logFile,
      rotation: {
        maxSize: '100MB',
        compressionLevel: 6,
        maxFiles: 10,
        maxAge: 7
      },
      console: false
    });
    ```

    **Sidecar logging pattern (recommended):**
    ```yaml
    # Main application writes to stdout
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: app
    spec:
      template:
        spec:
          containers:
          - name: app
            image: myapp:latest
            # Configure log-vibe to write to stdout only
            env:
            - name: LOG_TO_FILE
              value: "false"
          # Sidecar container collects logs and writes to disk
          - name: log-collector
            image: log-collector:latest
            volumeMounts:
            - name: logs
              mountPath: /logs
          volumes:
          - name: logs
            persistentVolumeClaim:
              claimName: log-pvc
    ```

    ### Cloud Logging Patterns

    **Google Cloud Logging:**
    ```typescript
    import { configure } from 'log-vibe';

    // Write to stdout, let Cloud Logging agent handle it
    configure({
      console: true,  // Cloud Logging picks up stdout
      useColors: false,  // Disable colors for cloud logs
      timestampFormat: 'iso'
    });

    // Or write to file for Cloud Logging agent
    configure({
      file: '/var/log/app/app.log',
      rotation: { maxSize: '100MB' }
    });
    ```

    **AWS CloudWatch:**
    ```typescript
    import { configure } from 'log-vibe';

    // Write to file for CloudWatch agent
    configure({
      file: '/var/log/nodejs/app.log',
      rotation: {
        maxSize: '100MB',
        pattern: 'daily',
        compressionLevel: 6
      },
      console: false
    });
    ```

    **CloudWatch agent configuration:**
    ```json
    {
      "logs": {
        "logs_collected": {
          "files": {
            "collect_list": [
              {
                "file_path": "/var/log/nodejs/app.log",
                "log_group_name": "/aws/nodejs/app",
                "log_stream_name": "{instance_id}"
              }
            ]
          }
        }
      }
    }
    ```

    **Azure Monitor:**
    ```typescript
    import { configure } from 'log-vibe';

    configure({
      file: '/var/log/app/app.log',
      rotation: { maxSize: '100MB' },
      console: false
    });
    ```

    **Log Analytics agent configuration:**
    ```yaml
    - name: app-logs
      path: /var/log/app/*.log
      type: file
    ```

    ### Dedicated Logging Server (Multi-Process)

    For applications requiring multi-process logging, use a dedicated logging server:

    **Architecture:**
    ```
    App Process 1 ──┐
    App Process 2 ──┼──> Logging Server ──> Disk
    App Process 3 ──┘
    ```

    **Logging server example:**
    ```typescript
    // server.js - Dedicated logging server
    import express from 'express';
    import { configure, log } from 'log-vibe';

    configure({
      file: './logs/central.log',
      rotation: {
        maxSize: '500MB',
        pattern: 'daily',
        compressionLevel: 6,
        maxFiles: 30,
        maxAge: 90
      }
    });

    const app = express();
    app.use(express.json());

    app.post('/log', (req, res) => {
      const { level, context, message, data } = req.body;
      log[level](context, message, data);
      res.sendStatus(200);
    });

    app.listen(3001);
    ```

    **Client applications send logs:**
    ```typescript
    // client.js - Application process
    import fetch from 'node-fetch';

    async function sendLog(level: string, context: string, message: string, data?: any) {
      await fetch('http://localhost:3001/log', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ level, context, message, data })
      }).catch(() => {});  // Don't throw
    }

    // Use in application
    await sendLog('info', 'App', 'Started');
    await sendLog('error', 'Database', 'Connection failed', { code: 'ECONNREFUSED' });
    ```

    ---

    ```

    This provides production deployment examples for common scenarios.
  </action>
  <verify>
    grep -n "Production Deployment\|Docker Deployment\|Kubernetes Deployment" README.md | head -5
  </verify>
  <done>
    Production Deployment section added with Docker, Kubernetes, and cloud examples
  </done>
</task>

<task type="auto">
  <name>Add links to TROUBLESHOOTING.md and MONITORING.md</name>
  <files>README.md</files>
  <action>
    Add links to the troubleshooting and monitoring guides in appropriate sections.

    1. Add to the "Transports" section after the cleanup subsection (around line 180):

    ```markdown
    ### Troubleshooting and Monitoring

    For production deployments, see:
    - **[Troubleshooting Guide](./docs/TROUBLESHOOTING.md)** - Common errors and solutions
    - **[Monitoring Guide](./docs/MONITORING.md)** - Health checks and alerting

    ```

    2. Add to the "Production Deployment" section after the dedicated logging server example:

    ```markdown
    ### Additional Documentation

    - **[Troubleshooting Guide](./docs/TROUBLESHOOTING.md)** - Diagnose and fix production issues
    - **[Monitoring Guide](./docs/MONITORING.md)** - Set up health checks and alerts

    ---

    ```

    This ensures users can easily find the detailed production documentation.
  </action>
  <verify>
    grep -n "docs/TROUBLESHOOTING.md\|docs/MONITORING.md" README.md
  </verify>
  <done>
    Links to TROUBLESHOOTING.md and MONITORING.md added in relevant sections
  </done>
</task>

</tasks>

<verification>
- Limitations section appears near top of README
- Multi-process limitation prominently documented as "NOT SUPPORTED"
- Workarounds for multi-process documented
- Docker deployment example with Dockerfile and docker-compose.yml
- Kubernetes deployment example with Deployment manifest
- Cloud logging patterns for GCP, AWS, Azure
- Dedicated logging server architecture example
- Links to TROUBLESHOOTING.md in Transports section
- Links to MONITORING.md in Transports section
- Links to both docs in Production Deployment section
- All deployment examples include log-vibe configuration
</verification>

<success_criteria>
- Users see multi-process limitation before using library
- Production deployment examples for all major platforms
- Cloud logging patterns clearly documented
- Links to troubleshooting and monitoring guides prominent
- Production-ready configurations provided
- Dedicated logging server pattern documented for multi-process scenarios
</success_criteria>

<output>
After completion, create `.planning/phases/06-error-handling-hardening/06-06-SUMMARY.md`
</output>
